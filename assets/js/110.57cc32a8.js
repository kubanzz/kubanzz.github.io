(window.webpackJsonp=window.webpackJsonp||[]).push([[110],{434:function(t,_,a){"use strict";a.r(_);var v=a(12),r=Object(v.a)({},(function(){var t=this,_=t._self._c;return _("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[_("h2",{attrs:{id:"一、海量数据处理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#一、海量数据处理"}},[t._v("#")]),t._v(" 一、海量数据处理")]),t._v(" "),_("blockquote",[_("p",[t._v("海量数据，指的就是数据量过大，导致数据无法一次性装入内存，无法短时间内快速处理的情况。")]),t._v(" "),_("ul",[_("li",[t._v("针对时间：可以利用"),_("strong",[t._v("算法 + 数据结构")]),t._v("：如Bloom filter/Hash/bit-map/堆/数据库或倒排索引/trie树")]),t._v(" "),_("li",[t._v("针对空间：则遵循"),_("strong",[t._v("大而化小，分而治之")]),t._v("（hash映射）")])]),t._v(" "),_("p",[t._v("而海量数据的处理又分为单机处理和集群处理")]),t._v(" "),_("ul",[_("li",[_("p",[t._v("单机处理：依次处理小部分数据，只要考虑cpu，内存，硬盘的数据交互。")])]),t._v(" "),_("li",[_("p",[t._v("集群处理：涉及到多台机器，适合分布式处理，并行计算，更多考虑节点和节点间的数据交互，例如Hadoop的MapReduce就是利用到多台机器进行并行处理。")])])])]),t._v(" "),_("h2",{attrs:{id:"二、海量数据处理方法总结"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#二、海量数据处理方法总结"}},[t._v("#")]),t._v(" 二、海量数据处理方法总结")]),t._v(" "),_("h3",{attrs:{id:"_2-1-bloom-filter"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-bloom-filter"}},[t._v("#")]),t._v(" 2.1 Bloom filter")]),t._v(" "),_("p",[t._v("适用范围：可以用来实现数据字典，进行数据的判重，或者集合求交集。")]),t._v(" "),_("p",[t._v("问题实例：")]),t._v(" "),_("h3",{attrs:{id:"_2-2-hashing"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-hashing"}},[t._v("#")]),t._v(" 2.2 Hashing")]),t._v(" "),_("p",[t._v("适用范围：快速查找，删除的基本数据结构，通常需要"),_("strong",[t._v("总数据量可以放入内存")]),t._v("。")]),t._v(" "),_("p",[t._v("问题实例：")]),t._v(" "),_("ol",[_("li",[t._v("海量日志数据，提取出某日访问百度次数最多的那个IP。")])]),t._v(" "),_("blockquote",[_("p",[t._v("IP的数目还是有限的（本质是一个int类型数字被划分成了4段），最多2^32个，所以可以考虑使用hash将ip直接存入内存，然后进行统计。")])]),t._v(" "),_("h3",{attrs:{id:"_2-3-bit-map"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-bit-map"}},[t._v("#")]),t._v(" 2.3 bit-map")]),t._v(" "),_("p",[t._v("适用范围：可进行数据的快速查找，判重，删除，一般来说数据范围是int的10倍以下。")]),t._v(" "),_("p",[t._v("问题实例：")]),t._v(" "),_("ol",[_("li",[t._v("已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。")])]),t._v(" "),_("blockquote",[_("p",[t._v("8位最多99 999 999，大概需要99m个bit，大概10几m字节的内存即可。")])]),t._v(" "),_("ol",{attrs:{start:"2"}},[_("li",[t._v("2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。")])]),t._v(" "),_("blockquote",[_("p",[t._v("通过bit-map存储，用2bitmap存储，或者用两个bitmap模拟，0表示不存在，1表示存在，2以上表示重复")])]),t._v(" "),_("h3",{attrs:{id:"_2-4-堆"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-堆"}},[t._v("#")]),t._v(" 2.4 堆")]),t._v(" "),_("p",[_("strong",[t._v("适用范围")]),t._v("：海量数据前n大，并且n比较小，"),_("strong",[t._v("堆可以放入内存")]),t._v("。")]),t._v(" "),_("p",[_("strong",[t._v("扩展")]),t._v("：双堆，一个最大堆与一个最小堆结合，可以用来维护中位数。")]),t._v(" "),_("p",[_("strong",[t._v("问题实例")]),t._v("：")]),t._v(" "),_("ol",[_("li",[t._v("100w个数中找最大的前100个数。")])]),t._v(" "),_("blockquote",[_("p",[t._v("用一个100个元素大小的最小堆即可。")])]),t._v(" "),_("h3",{attrs:{id:"_2-5-双层桶划分-分而治之"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-双层桶划分-分而治之"}},[t._v("#")]),t._v(" 2.5 双层桶划分（分而治之）")]),t._v(" "),_("p",[t._v("适用范围：第k大，中位数，不重复或重复的数字")]),t._v(" "),_("p",[t._v("基本原理及要点：因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。可以通过多次缩小，双层只是一个例子。")]),t._v(" "),_("h3",{attrs:{id:"_2-6-数据库索引"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-6-数据库索引"}},[t._v("#")]),t._v(" 2.6 数据库索引")]),t._v(" "),_("p",[t._v("适用范围：大数据量的增删改查")]),t._v(" "),_("p",[t._v("基本原理及要点：利用数据的设计实现方法，对海量数据的增删改查进行处理。")]),t._v(" "),_("h3",{attrs:{id:"_2-7-倒排索引-inverted-index"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-7-倒排索引-inverted-index"}},[t._v("#")]),t._v(" 2.7 倒排索引(Inverted index)")]),t._v(" "),_("p",[t._v("适用范围：搜索引擎，关键字查询")]),t._v(" "),_("p",[t._v("基本原理及要点：为何叫倒排索引？一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。")]),t._v(" "),_("h3",{attrs:{id:"_2-8-外排序"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-8-外排序"}},[t._v("#")]),t._v(" 2.8 外排序")]),t._v(" "),_("p",[t._v("适用范围：大数据的排序，去重")]),t._v(" "),_("h3",{attrs:{id:"_2-9-trie树"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-9-trie树"}},[t._v("#")]),t._v(" 2.9 trie树")]),t._v(" "),_("p",[t._v("适用范围：数据量大，重复多，但是数据种类小可以放入内存")]),t._v(" "),_("h3",{attrs:{id:"_2-10-分布式处理-mapreduce"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#_2-10-分布式处理-mapreduce"}},[t._v("#")]),t._v(" 2.10 分布式处理 mapreduce")]),t._v(" "),_("p",[t._v("适用范围：数据量大，但是数据种类小可以放入内存")]),t._v(" "),_("p",[t._v("基本原理及要点：将数据交给不同的机器去处理，数据划分，结果归约。")]),t._v(" "),_("h2",{attrs:{id:"三、参考"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#三、参考"}},[t._v("#")]),t._v(" 三、参考")]),t._v(" "),_("ul",[_("li",[_("a",{attrs:{href:"https://blog.csdn.net/v_JULY_v/article/details/6279498",target:"_blank",rel:"noopener noreferrer"}},[t._v("大数处理一*"),_("OutboundLink")],1)]),t._v(" "),_("li",[_("a",{attrs:{href:"https://juejin.cn/post/6844903519640616967#heading-6",target:"_blank",rel:"noopener noreferrer"}},[t._v("大数处理二"),_("OutboundLink")],1)])])])}),[],!1,null,null,null);_.default=r.exports}}]);